{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccd8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T14:57:34.209054Z",
     "start_time": "2023-07-16T14:57:27.647475Z"
    }
   },
   "outputs": [],
   "source": [
    "#conda activate tf2, tf2.10\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "from glob import glob\n",
    "try:\n",
    "    from tensorflow.python.keras.applications import ResNet50\n",
    "    from tensorflow.python.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "    from tensorflow.python.keras import backend as K\n",
    "except:\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "    from tensorflow.keras import backend as K \n",
    "    \n",
    "from time import time\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    K.set_image_data_format('channels_last')\n",
    "print(K.image_data_format())\n",
    "\n",
    "print(tf.__version__) #2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b66bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T14:57:38.520721Z",
     "start_time": "2023-07-16T14:57:38.517379Z"
    }
   },
   "outputs": [],
   "source": [
    "################# SET PARAMS ##########################\n",
    "#layers\n",
    "block = ['conv2']\n",
    "LAYER_TYPE = 'act'\n",
    "MAX_SIDE = 32\n",
    "\n",
    "#flow stims\n",
    "scl_factor = 0.5\n",
    "N_INSTANCES = 3\n",
    "trial_len = 75//2# n frames\n",
    "stride = 1\n",
    "\n",
    "model_name = 'res50_shifted'\n",
    "\n",
    "## SAMPLING\n",
    "seed = 0\n",
    "fmap_samp_method = 'maxFr'\n",
    "neur_samp_method = 'maxNr'\n",
    "n_fmaps_to_sample = 40\n",
    "samples_per_fmap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d59bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T14:57:42.443339Z",
     "start_time": "2023-07-16T14:57:40.186203Z"
    }
   },
   "outputs": [],
   "source": [
    "############## LOAD MODEL ############################\n",
    "\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers[-1].activation = tf.keras.activations.relu\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "if tf.__version__[0] == '2':\n",
    "    input_shape = model.layers[0].output_shape[0][1:3]\n",
    "else:\n",
    "    input_shape = model.layers[0].output_shape[1:3]\n",
    "\n",
    "conv_layers = []\n",
    "act_layers = []\n",
    "fc_layers = []\n",
    "current_convs = []\n",
    "for li,layer in enumerate(model.layers):\n",
    "    type_name = str(type(model.layers[li]))\n",
    "    if 'Conv2D' in type_name:\n",
    "        current_convs.append((li,layer.name,layer))\n",
    "\n",
    "    elif 'Activation' in type_name:\n",
    "        #print('-',[(lci,lcname) for lci,lcname,cl in current_convs])\n",
    "\n",
    "        act_layers.append((li,layer.name,layer))\n",
    "        #print('*',li,layer.name)\n",
    "        for lc,_,cl in current_convs:\n",
    "            assert layer.output.shape.as_list() == cl.output.shape.as_list()\n",
    "        conv_layers.append(current_convs)\n",
    "        current_convs = []\n",
    "    elif 'Dense' in type_name:\n",
    "        fc_layers.append((li,layer.name,layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa897a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T15:00:55.654885Z",
     "start_time": "2023-07-16T15:00:45.224326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_stims 88\n",
      "frames_per_stim 37\n",
      "*INSTANCE 0 ...........\n",
      "*INSTANCE 1 ...........\n",
      "*INSTANCE 2 ...........\n"
     ]
    }
   ],
   "source": [
    "############# LOAD FLOW STIM FRAMES #################\n",
    "\n",
    "\n",
    "orig_shape = (800,600)\n",
    "scl_factor = 0.5\n",
    "\n",
    "mydirs = list(map(str,range(0,360,45)))\n",
    "categories = ['grat_W12','grat_W1','grat_W2',\n",
    "              'neg1dotflow_D1_bg','neg3dotflow_D1_bg','neg1dotflow_D2_bg','neg3dotflow_D2_bg',\n",
    "              'pos1dotflow_D1_bg','pos3dotflow_D1_bg','pos1dotflow_D2_bg','pos3dotflow_D2_bg']\n",
    "\n",
    "topdir = 'flowstims'\n",
    "NDIRS = len(mydirs)\n",
    "tot_stims = len(categories)*NDIRS\n",
    "print('tot_stims',tot_stims,flush=True)\n",
    "frames_per_stim = (trial_len//stride)\n",
    "print('frames_per_stim',frames_per_stim)\n",
    "\n",
    "flow_datasets = createFlowDataset(categories, topdir, mydirs, orig_shape, input_shape, scl_factor, N_INSTANCES, trial_len, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "442ac318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T15:10:40.818801Z",
     "start_time": "2023-07-16T15:10:40.739545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABZCAYAAAAw7++8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB60lEQVR4nO3WMW7iQBiA0QFxAyoOQMkpEBUloqTgYJwlLcdBoqFzqpW222TjJNKn92r712is+TyLaZqmAUDW8rcXAMD3EnqAOKEHiBN6gDihB4gTeoA4oQeIE3qAuNVHHzwcDp8avNlsxuVyGcvlPP+S5/M5brfbeL1es8xbrVbjer2O9Xr9pTn7/X6W9fzLZ/f/b6fTaWy321nWsVgsxtvb27jf77PMG2OM3W43jsfjf737U/s/xte+wR/Fc/FT3+B8Po/H4zHbvMq5+Mj+u9EDxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QJPUCc0APECT1AnNADxAk9QJzQA8QtpmmafnsRAHwfN3qAOKEHiBN6gDihB4gTeoA4oQeIE3qAOKEHiBN6gLh3fnY1qw1V4yoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 400x100 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show example of sequence of frames generated for a stimulus trial\n",
    "n_frames_to_show = 4\n",
    "interval = 8\n",
    "\n",
    "f, axes = subps(1,n_frames_to_show, 1, 1)\n",
    "for i in range(n_frames_to_show):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(flow_datasets[0][i*interval].reshape(input_shape), vmin=0, vmax=255, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e487d743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T21:27:18.028336Z",
     "start_time": "2023-07-13T21:27:18.011781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2_block1_1_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block1_2_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block1_out: 256 fmaps\n",
      "  spacedims [32, 32, 256]\n",
      "  Total units: 262144\n",
      "conv2_block2_1_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block2_2_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block2_out: 256 fmaps\n",
      "  spacedims [32, 32, 256]\n",
      "  Total units: 262144\n",
      "conv2_block3_1_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block3_2_relu: 64 fmaps\n",
      "  spacedims [32, 32, 64]\n",
      "  Total units: 65536\n",
      "conv2_block3_out: 256 fmaps\n",
      "  spacedims [32, 32, 256]\n",
      "  Total units: 262144\n"
     ]
    }
   ],
   "source": [
    "############# GET LAYERS #################\n",
    "\n",
    "\n",
    "block_test = lambda name: any([b in name for b in block])\n",
    "block_is = [li for li,lrs in enumerate(conv_layers) if any([block_test(lname) for _,lname,_ in lrs])]\n",
    "\n",
    "block_layers = [(li,l) for li,l in enumerate(model.layers) if block_test(l.name)]\n",
    "my_act_layers = [act_layers[li] for li in block_is]\n",
    "\n",
    "if LAYER_TYPE == 'conv':\n",
    "    mylayers =[]\n",
    "    for li in block_is:\n",
    "        mylayers += conv_layers[li]\n",
    "    my_conv_ls = [[l] for l in mylayers]\n",
    "    \n",
    "elif LAYER_TYPE == 'act':\n",
    "    mylayers = my_act_layers\n",
    "    my_conv_ls = [conv_layers[li] for li in block_is]\n",
    "    \n",
    "elif LAYER_TYPE == 'dense':\n",
    "    mylayers = fc_layers\n",
    "    my_conv_ls = None\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "layers_to_use = [l for li,lname,l in mylayers]\n",
    "Nlayers = len(layers_to_use)\n",
    "\n",
    "input_layer = model.layers[0]\n",
    "\n",
    "if LAYER_TYPE == 'dense':\n",
    "    chan_idx = 1\n",
    "    all_layer_totfmaps = [lconv.output.shape.as_list()[chan_idx] for lconv in layers_to_use]\n",
    "    all_layer_spacedims = [[1,1] + [all_layer_totfmaps[li]] for li,lconv in enumerate(layers_to_use)]\n",
    "    out_pads = None\n",
    "else:\n",
    "    out_pads = [max(1,(layers_to_use[li].output.shape.as_list()[1] - MAX_SIDE)//2 ) for li in range(len(layers_to_use))]\n",
    "\n",
    "    chan_idx = 3\n",
    "    img_idxs = [1,2]\n",
    "    all_layer_totfmaps = [lconv.output.shape.as_list()[chan_idx] for lconv in layers_to_use]\n",
    "    all_layer_spacedims = [list(np.array(layers_to_use[li].output.shape.as_list())[img_idxs]-2*out_pads[li]) + \\\n",
    "                           [all_layer_totfmaps[li]] for li,lconv in enumerate(layers_to_use)]\n",
    "\n",
    "all_layer_nunits = [np.prod(lspcd) for lspcd in all_layer_spacedims]\n",
    "\n",
    "for li,l in enumerate(layers_to_use):\n",
    "    \n",
    "    print(f'{l.name}: {all_layer_totfmaps[li]} fmaps')\n",
    "    print('  spacedims',all_layer_spacedims[li])\n",
    "    print('  Total units:',all_layer_nunits[li],flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e64608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T21:40:08.846136Z",
     "start_time": "2023-07-13T21:29:03.999337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot # of images: 88 * 37 = 3256\n",
      "batchsize 32 -- # of batches: 102\n",
      "INSTANCE 0\n",
      "0 (3.0s) 1 (0.6s) 2 (0.6s) 3 (0.6s) 4 (0.5s) 5 (0.5s) 6 (0.5s) 7 (0.6s) 8 (0.6s) 9 (0.5s) 10 (0.6s) 11 (0.6s) 12 (0.6s) 13 (0.5s) 14 (0.5s) 15 (0.5s) 16 (0.5s) 17 (0.5s) 18 (0.5s) 19 (0.5s) 20 (0.5s) 21 (0.5s) 22 (0.5s) 23 (0.5s) 24 (0.5s) 25 (0.5s) 26 (0.5s) 27 (0.5s) 28 (0.5s) 29 (0.5s) 30 (0.5s) 31 (0.5s) 32 (0.5s) 33 (0.5s) 34 (0.5s) 35 (0.5s) 36 (0.5s) 37 (0.5s) 38 (0.5s) 39 (0.5s) 40 (0.6s) 41 (0.4s) 42 (0.5s) 43 (0.5s) 44 (0.5s) 45 (0.5s) 46 (0.5s) 47 (0.5s) 48 (0.5s) 49 (0.5s) 50 (0.5s) 51 (0.5s) 52 (0.5s) 53 (0.5s) 54 (0.5s) 55 (0.5s) 56 (0.5s) 57 (0.4s) 58 (0.5s) 59 (0.4s) 60 (0.5s) 61 (0.5s) 62 (0.5s) 63 (0.5s) 64 (0.5s) 65 (0.5s) 66 (0.5s) 67 (0.5s) 68 (0.5s) 69 (0.6s) 70 (0.5s) 71 (0.5s) 72 (0.5s) 73 (0.5s) 74 (0.5s) 75 (0.5s) 76 (0.5s) 77 (0.5s) 78 (0.6s) 79 (0.5s) 80 (0.5s) 81 (0.5s) 82 (0.5s) 83 (0.5s) 84 (0.5s) 85 (0.5s) 86 (0.5s) 87 (0.5s) 88 (0.5s) 89 (0.5s) 90 (0.5s) 91 (0.5s) 92 (0.5s) 93 (0.5s) 94 (0.5s) 95 (0.5s) 96 (0.5s) 97 (0.5s) 98 (0.5s) 99 (0.5s) 100 (0.6s) 101 (0.4s)  Tot time = 228.7\n",
      "INSTANCE 1\n",
      "0 (0.5s) 1 (0.5s) 2 (0.6s) 3 (0.6s) 4 (0.5s) 5 (0.6s) 6 (0.5s) 7 (0.5s) 8 (0.5s) 9 (0.5s) 10 (0.5s) 11 (0.6s) 12 (0.5s) 13 (0.5s) 14 (0.6s) 15 (0.5s) 16 (0.6s) 17 (0.5s) 18 (0.5s) 19 (0.5s) 20 (0.5s) 21 (0.5s) 22 (0.5s) 23 (0.5s) 24 (0.5s) 25 (0.5s) 26 (0.5s) 27 (0.5s) 28 (0.5s) 29 (0.5s) 30 (0.5s) 31 (0.5s) 32 (0.5s) 33 (0.5s) 34 (0.5s) 35 (0.5s) 36 (0.5s) 37 (0.6s) 38 (0.5s) 39 (0.5s) 40 (0.5s) 41 (0.6s) 42 (0.5s) 43 (0.5s) 44 (0.5s) 45 (0.5s) 46 (0.5s) 47 (0.5s) 48 (0.5s) 49 (0.5s) 50 (0.5s) 51 (0.5s) 52 (0.5s) 53 (0.5s) 54 (0.5s) 55 (0.5s) 56 (0.5s) 57 (0.5s) 58 (0.5s) 59 (0.5s) 60 (0.5s) 61 (0.5s) 62 (0.5s) 63 (0.5s) 64 (0.6s) 65 (0.5s) 66 (0.5s) 67 (0.5s) 68 (0.5s) 69 (0.5s) 70 (0.5s) 71 (0.5s) 72 (0.5s) 73 (0.5s) 74 (0.6s) 75 (0.5s) 76 (0.5s) 77 (0.5s) 78 (0.5s) 79 (0.5s) 80 (0.6s) 81 (0.5s) 82 (0.5s) 83 (0.6s) 84 (0.5s) 85 (0.5s) 86 (0.5s) 87 (0.5s) 88 (0.6s) 89 (0.5s) 90 (0.6s) 91 (0.5s) 92 (0.5s) 93 (0.5s) 94 (0.6s) 95 (0.5s) 96 (0.5s) 97 (0.5s) 98 (0.5s) 99 (0.6s) 100 (0.5s) 101 (0.4s)  Tot time = 217.9\n",
      "INSTANCE 2\n",
      "0 (0.5s) 1 (0.5s) 2 (0.6s) 3 (0.6s) 4 (0.5s) 5 (0.5s) 6 (0.5s) 7 (0.5s) 8 (0.5s) 9 (0.6s) 10 (0.5s) 11 (0.6s) 12 (0.5s) 13 (0.5s) 14 (0.5s) 15 (0.5s) 16 (0.5s) 17 (0.5s) 18 (0.5s) 19 (0.5s) 20 (0.5s) 21 (0.5s) 22 (0.5s) 23 (0.5s) 24 (0.5s) 25 (0.5s) 26 (0.5s) 27 (0.5s) 28 (0.5s) 29 (0.5s) 30 (0.5s) 31 (0.5s) 32 (0.5s) 33 (0.5s) 34 (0.6s) 35 (0.5s) 36 (0.5s) 37 (0.5s) 38 (0.5s) 39 (0.5s) 40 (0.6s) 41 (0.5s) 42 (0.5s) 43 (0.6s) 44 (0.5s) 45 (0.5s) 46 (0.5s) 47 (0.6s) 48 (0.5s) 49 (0.5s) 50 (0.6s) 51 (0.5s) 52 (0.5s) 53 (0.5s) 54 (0.5s) 55 (0.5s) 56 (0.5s) 57 (0.5s) 58 (0.5s) 59 (0.5s) 60 (0.5s) 61 (0.5s) 62 (0.6s) 63 (0.5s) 64 (0.5s) 65 (0.5s) 66 (0.5s) 67 (0.5s) 68 (0.6s) 69 (0.5s) 70 (0.5s) 71 (0.5s) 72 (0.5s) 73 (0.5s) 74 (0.5s) 75 (0.5s) 76 (0.5s) 77 (0.5s) 78 (0.5s) 79 (0.5s) 80 (0.6s) 81 (0.5s) 82 (0.5s) 83 (0.6s) 84 (0.5s) 85 (0.5s) 86 (0.5s) 87 (0.5s) 88 (0.5s) 89 (0.6s) 90 (0.5s) 91 (0.6s) 92 (0.5s) 93 (0.5s) 94 (0.5s) 95 (0.5s) 96 (0.5s) 97 (0.5s) 98 (0.5s) 99 (0.5s) 100 (0.5s) 101 (0.4s)  Tot time = 217.0\n"
     ]
    }
   ],
   "source": [
    "####################### COMPUTE ################\n",
    "\n",
    "all_layer_outs = K.function(inputs=[input_layer.input], \n",
    "                          outputs=[lconv.output for lconv in layers_to_use])\n",
    "\n",
    "TOL = 0\n",
    "layer_outputs = {}\n",
    "\n",
    "\n",
    "n_orig_imgs = tot_stims\n",
    "n_shifts = frames_per_stim\n",
    "n_shifted_imgs = n_orig_imgs * n_shifts\n",
    "\n",
    "\n",
    "#batches for imgs and shifts\n",
    "maxBatchsize = 32 #max n of images to be used as input simultaneously (prevent memory crashes)\n",
    "\n",
    "nBatches = int(np.ceil(n_shifted_imgs/float(maxBatchsize)))\n",
    "\n",
    "print('tot # of images:',n_orig_imgs,'*',n_shifts,'=',n_shifted_imgs)\n",
    "print('batchsize',maxBatchsize,'-- # of batches:',nBatches)\n",
    "\n",
    "def reshape_flow_img(raveled_1chan_img):\n",
    "    return np.moveaxis(np.tile(raveled_1chan_img.reshape(input_shape),(3,1,1)),0,-1)\n",
    "\n",
    "\n",
    "layer_outputs = []\n",
    "layer_output = []\n",
    "for li in range(len(layers_to_use)):\n",
    "    layer_outputs.append(np.zeros([n_shifted_imgs] + all_layer_spacedims[li], dtype='float32'))\n",
    "    layer_output.append(None)\n",
    "for insti in range(N_INSTANCES):\n",
    "    extX = flow_datasets[insti]\n",
    "    assert extX.shape[0] == n_shifted_imgs\n",
    "\n",
    "    print('INSTANCE',insti)\n",
    "    start0 = time()\n",
    "    for bb in range(nBatches):\n",
    "        start = time()\n",
    "        print(bb,end=' ',flush=True)\n",
    "\n",
    "        #grab imgs and reshape 'em\n",
    "\n",
    "        batch = np.array([preprocess_input(reshape_flow_img(im)) \\\n",
    "             for im in extX[bb*maxBatchsize:(bb+1)*maxBatchsize]])\n",
    "\n",
    "        batch_output = all_layer_outs([batch])\n",
    "        print('(%.1fs) ' % (time()-start),end='',flush=True)\n",
    "        \n",
    "        for li in range(len(layers_to_use)):\n",
    "            hh, ww = all_layer_spacedims[li][:2]\n",
    "\n",
    "            if out_pads is None:\n",
    "                assert batch_output[li].ndim == 2\n",
    "                l_batch_output = batch_output[li][:,None,None,:]\n",
    "                \n",
    "            else:\n",
    "                l_batch_output = batch_output[li][:,out_pads[li]:hh+out_pads[li],out_pads[li]:ww+out_pads[li],:]\n",
    "            if bb == 0:\n",
    "                layer_output[li] = l_batch_output\n",
    "            else:\n",
    "                #append to current output\n",
    "                layer_output[li] = np.concatenate([layer_output[li],l_batch_output])\n",
    "\n",
    "\n",
    "    for li in range(len(layers_to_use)):\n",
    "        layer_outputs[li] += layer_output[li]\n",
    "    print(' Tot time = %.1f' % (time() - start0),flush=True)\n",
    "for li in range(len(layers_to_use)):\n",
    "    layer_outputs[li] /= N_INSTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e65b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T21:41:40.205148Z",
     "start_time": "2023-07-13T21:40:42.959210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities per img: 012345678"
     ]
    }
   ],
   "source": [
    "################### SUMMARIZE ACTIVITY ###########\n",
    "\n",
    "print('Activities per img:',end=' ')\n",
    "for li in range(len(layers_to_use)):\n",
    "    print(li,end='',flush=True)\n",
    "    layer_output_ = layer_outputs[li].copy()\n",
    "    layer_output_[layer_output_ < 0] = 0\n",
    "    \n",
    "\n",
    "    nfmaps = layer_output_.shape[3]\n",
    "    orig_per_img_output = np.moveaxis(layer_output_.copy(),-1,1).reshape([n_orig_imgs, n_shifts, nfmaps, -1])\n",
    "    orig_per_img_output = np.moveaxis(orig_per_img_output,1,-1)\n",
    "\n",
    "    #normalize each img by the max, to prevent results being dominated by a few highly-activating images\n",
    "    layer_output_ /= from0to1(layer_output_.max((1,2,3),keepdims=1))\n",
    "\n",
    "    per_img_output = np.moveaxis(layer_output_,-1,1).reshape([n_orig_imgs, n_shifts, nfmaps, -1])\n",
    "    per_img_output = np.moveaxis(per_img_output,1,-1)\n",
    "    \n",
    "\n",
    "    #get the avg response (across time) of a neuron to a particular stim dir\n",
    "    #then, compute the max or mean across these\n",
    "    tot_n_neurons = np.prod(layer_output_.shape[1:])\n",
    "\n",
    "    \n",
    "    neurons_maxs = np.zeros(per_img_output.shape[1:3])\n",
    "    neurons_means = np.zeros(per_img_output.shape[1:3])#np.zeros(tot_n_neurons)\n",
    "\n",
    "    for imi in range(n_orig_imgs):\n",
    "        im_avgs = per_img_output[imi].mean(2) #avging across time\n",
    "        neurons_maxs = np.max([neurons_maxs,im_avgs],0)\n",
    "        neurons_means += im_avgs\n",
    "    neurons_means /= n_orig_imgs\n",
    "\n",
    "    idxs = neurons_maxs.mean(1).argsort()\n",
    "\n",
    "    if li == 0:\n",
    "        all_neurons_maxs = neurons_maxs\n",
    "        all_neurons_means = neurons_means\n",
    "        all_per_img_output = orig_per_img_output\n",
    "    else:\n",
    "        all_neurons_maxs = np.concatenate([all_neurons_maxs, neurons_maxs],0)\n",
    "        all_neurons_means = np.concatenate([all_neurons_means, neurons_means],0)\n",
    "        all_per_img_output = np.concatenate([all_per_img_output, orig_per_img_output],1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5f132a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T21:41:42.253981Z",
     "start_time": "2023-07-13T21:41:42.177319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "############# SAMPLE NEURONS ###########\n",
    "\n",
    "nfmaps,n_neurons_per_fmap = all_neurons_maxs.shape\n",
    "layer_is_per_fmap = np.concatenate([li*np.ones(nfs) for li,nfs in enumerate(all_layer_totfmaps)])\n",
    "np.random.seed(seed)\n",
    "\n",
    "maxsmean = all_neurons_maxs.mean(1)\n",
    "n_fmaps_to_sample_ = min(n_fmaps_to_sample, (~np.isclose(maxsmean,0)).sum())\n",
    "if fmap_samp_method == 'maxFr':\n",
    "    top_fmaps = np.random.choice(range(nfmaps),n_fmaps_to_sample_,False,maxsmean/maxsmean.sum())\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "#pick active neurons in each of these fmaps\n",
    "sampled_neurons = []\n",
    "\n",
    "samples_per_fmap = min(samples_per_fmap,all_neurons_means.shape[1])\n",
    "for fi in top_fmaps:\n",
    "    if neur_samp_method == 'maxNr':\n",
    "        neuron_vals = all_neurons_maxs[fi]\n",
    "        samples_per_fmap_ = min(samples_per_fmap, (~np.isclose(neuron_vals,0)).sum())\n",
    "        top_nis = np.random.choice(range(n_neurons_per_fmap),samples_per_fmap_,False,neuron_vals/neuron_vals.sum())\n",
    "    else:\n",
    "        raise ValueError\n",
    "    sampled_neurons += list(fi*n_neurons_per_fmap + top_nis)\n",
    "sampled_neurons = np.array(sampled_neurons)\n",
    "n_neurons_to_pick = len(sampled_neurons)\n",
    "print(n_neurons_to_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0290c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T21:41:45.764920Z",
     "start_time": "2023-07-13T21:41:44.931237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res50_shifted_act_i3_n2000_w32_SCL0_5_TL37_conv2_maxFr_maxNr\n"
     ]
    }
   ],
   "source": [
    "######### BUILD TENSOR ##########\n",
    "###BUILD TENSOR from psts\n",
    "\n",
    "#helper ftn\n",
    "def get_neuron_pos(ni):\n",
    "    \"\"\"from sampled indices ni, get original indices back (fmap, posi, posj, raveled_idx)\"\"\"\n",
    "    fi = ni // n_neurons_per_fmap\n",
    "    li = layer_is_per_fmap[fi]\n",
    "    ij = ni % n_neurons_per_fmap\n",
    "    ii = ij // ww\n",
    "    jj = ij % ww\n",
    "    return li,fi,ii,jj,ij\n",
    "\n",
    "assert n_orig_imgs//NDIRS == len(categories)\n",
    "\n",
    "tensorX = np.zeros((n_neurons_to_pick,len(categories),NDIRS,n_shifts))\n",
    "neurons_used = np.empty((n_neurons_to_pick,5),dtype='int')\n",
    "\n",
    "\n",
    "#collect psts for those sampled neurons\n",
    "for nii,ni in enumerate(sampled_neurons):\n",
    "    \n",
    "    li, fi, ii, jj, posi = get_neuron_pos(ni)\n",
    "    neurons_used[nii] = [li, fi, ii, jj, posi]\n",
    "    \n",
    "\n",
    "    for cati in range(len(categories)):\n",
    "        \n",
    "        pst = all_per_img_output[cati*NDIRS:(cati+1)*NDIRS,fi,posi,:]\n",
    "        tensorX[nii,cati] = pst\n",
    "        \n",
    "\n",
    "\n",
    "SUFFIX = f\"{model_name}_{LAYER_TYPE}_i{N_INSTANCES}_n{n_neurons_to_pick}_w{ww}_SCL{str(scl_factor).replace('.','_')}_TL{trial_len}_{'_'.join(block)}_{fmap_samp_method}_{neur_samp_method}\"\n",
    "if seed > 0:\n",
    "    SUFFIX += f'_seed{seed}'\n",
    "\n",
    "print(SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f09af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T16:01:51.433150Z",
     "start_time": "2022-12-09T16:01:51.194082Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(f'tensor4d_{SUFFIX}.npy',tensorX)\n",
    "print(f'tensor4d_{SUFFIX}.npy','Saved.')\n",
    "\n",
    "np.save(f'neurons_used_{SUFFIX}.npy',neurons_used)\n",
    "print(f'neurons_used_{SUFFIX}.npy','Saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.10]",
   "language": "python",
   "name": "conda-env-tf2.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
